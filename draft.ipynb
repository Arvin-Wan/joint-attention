{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiongcw/y/envs/temp/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/xiongcw/y/envs/temp/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# bert_base='./pretrain/bert-base-uncased/'\n",
    "bert_base = \"./pretrain/deberta-v3-large\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOS is  there a delta          flight from denver              to  san               francisco          EOS\t\n",
    " O   O  O     O B-airline_name O      O    B-fromloc.city_name O   B-toloc.city_name I-toloc.city_name \n",
    "atis_flight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁[',\n",
       " 'cl',\n",
       " 's',\n",
       " ']',\n",
       " '▁BOS',\n",
       " '▁what',\n",
       " '▁are',\n",
       " '▁the',\n",
       " '▁nonstop',\n",
       " '▁flights',\n",
       " '▁on',\n",
       " '▁america',\n",
       " '▁west',\n",
       " '▁or',\n",
       " '▁southwest',\n",
       " '▁air',\n",
       " '▁from',\n",
       " '▁kansas',\n",
       " '▁city',\n",
       " '▁to',\n",
       " '▁bur',\n",
       " 'bank',\n",
       " '▁on',\n",
       " '▁saturday',\n",
       " '▁may',\n",
       " '▁twenty',\n",
       " '▁two',\n",
       " '▁EOS']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = \"[cls] BOS what are the nonstop flights on america west or southwest air from kansas city to burbank on saturday may twenty two EOS\"\n",
    "# inputlit = inputs.split(\" \")\n",
    "# for i in inputlit:\n",
    "#     token = bert_tokenizer.tokenize(i)\n",
    "#     print(i,\"\\t\", token)\n",
    "token = bert_tokenizer.tokenize(inputs)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (True,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,),\n",
       " (False,)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = \"[cls] BOS what are the nonstop flights on america west or southwest air from kansas city to burbank on saturday may twenty two EOS\"\n",
    "\n",
    "lit = [tuple(map(lambda s: s == \"B\", t )) for t in inputs]\n",
    "lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randint(low = 1,high=10,size = (3,2,4)).float()\n",
    "b = torch.tensor([-1,-1,-1,-1])\n",
    "\n",
    "c = a.mean(1)\n",
    "print(c.shape)\n",
    "# print(a,\"\\t\", a.shape)\n",
    "# print(b,\"\\t\",b.shape)\n",
    "# c = a *b\n",
    "# print(c, \"\\t\", c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1434,  0.3087, -0.2963,  0.0805],\n",
      "        [ 0.2636,  0.0529, -0.2220, -0.3518]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "ENV_SEED = 1231\n",
    "torch.manual_seed(ENV_SEED)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,hidden_dim):\n",
    "        super(Model,self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(hidden_dim, hidden_dim //2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Model(4)\n",
    "model.cuda()\n",
    "inputs = torch.randn(size=(2,4))\n",
    "\n",
    "# output = model(inputs)\n",
    "print(model.linear.weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wef': 2, 'fff': 3}\n"
     ]
    }
   ],
   "source": [
    "dic1 = {\"wef\":2}\n",
    "dic2 = {\"fff\":3}\n",
    "\n",
    "dic1.update(dic2)\n",
    "print(dic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 3.],\n",
      "        [4., 3., 2.]])\n",
      "tensor([1, 2])\n",
      "tensor(4.6472)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "loss_function_2 = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "a = torch.randint(low = 1, high=5, size=(2,3)).float()\n",
    "b = torch.randint(low=1,high=3, size=(1,2)).view(-1)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "print(loss_function_2(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31853973865509033\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 预测分数 (logits)\n",
    "pred_score = torch.tensor([[2.0, 1.0, 0.1],\n",
    "                           [0.5, 2.5, 0.3]])\n",
    "\n",
    "# 目标标签\n",
    "target = torch.tensor([0, 1])\n",
    "\n",
    "# 创建 CrossEntropyLoss 实例\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 计算损失\n",
    "loss = criterion(pred_score, target)\n",
    "print(loss.item())  # 输出: 0.318\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from class A\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    some_attribute = \"Hello from class A\"\n",
    "\n",
    "class B(A):\n",
    "    @classmethod\n",
    "    def some_class_method(cls):\n",
    "        # 访问类A中的类属性\n",
    "        print(cls.some_attribute)\n",
    "\n",
    "# 调用类方法\n",
    "B.some_class_method()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 36.556358337402344\n",
      "Decoded tags: [[4, 0, 1, 1, 0, 1, 3, 2, 0, 1], [4, 0, 0, 2, 0, 2, 1, 3, 0, 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiongcw/y/envs/temp/lib/python3.9/site-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:530.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "\n",
    "class CRFModel(nn.Module):\n",
    "    def __init__(self, num_tags):\n",
    "        super(CRFModel, self).__init__()\n",
    "        self.num_tags = num_tags\n",
    "        self.crf = CRF(num_tags, batch_first=True)\n",
    "\n",
    "    def forward(self, emissions, tags, mask):\n",
    "        # 计算 CRF 损失\n",
    "        loss = -self.crf(emissions, tags, mask=mask)\n",
    "        return loss\n",
    "\n",
    "    def decode(self, emissions, mask):\n",
    "        # 使用 CRF 进行解码\n",
    "        return self.crf.decode(emissions, mask=mask)\n",
    "\n",
    "# 示例参数\n",
    "num_tags = 5\n",
    "seq_length = 10\n",
    "batch_size = 2\n",
    "\n",
    "# 创建模型\n",
    "model = CRFModel(num_tags)\n",
    "\n",
    "# 示例输入\n",
    "emissions = torch.randn(batch_size, seq_length, num_tags)\n",
    "tags = torch.randint(0, num_tags, (batch_size, seq_length))\n",
    "mask = torch.ones(batch_size, seq_length, dtype=torch.uint8)\n",
    "\n",
    "# 计算损失\n",
    "loss = model(emissions, tags, mask)\n",
    "print(\"Loss:\", loss.item())\n",
    "\n",
    "# 解码\n",
    "decoded_tags = model.decode(emissions, mask)\n",
    "print(\"Decoded tags:\", decoded_tags)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "temp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
